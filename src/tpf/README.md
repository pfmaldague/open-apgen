# README for the TOL compare capability

The TOL compare program features several subsystems:

1. the parser
2. the command interpreter
3. the record processor

## Flex / Bison parser

The parser is re-entrant; this is a relatively new (May 2020) addition to APGenX. The gramgen grammar generator, which was initially designed to generate the AAF grammar based on a very concise _skeleton file_, was retrofitted so it could generate a re-entrant TOL parser as well.

Another "first" for APGenX is that the flex-based TOL token analyzer makes use of "start conditions", a powerful feature of flex that makes token recognition context-dependent. This is used for two purposes:
1. Recognize time values that occur at the beginning of a record (the "time stamp") as opposed to somewhere else in the record, e. g. in an activity attribute.
2. Parse activity names containing (almost) arbitrary characters. While the type of an activity must conform to the same restrictions as variable names in most programming languages, activity names are not subject to the same restrictions. Because they are not quoted in the TOL format, this makes parsing somewhat challenging. A start condition provides an easy way to solve the problem.

## Command Interpreter

The interpreter starts by analyzing the command to figure out what resources it will need to marshal. Since we don't (yet) have a full-fledged command language, we make a few guesses as to what the commands will look like. Keep in mind that the purpose of each command is to learn _something_ about the differences between 2 TOLs, if any.  Such differences must be based on measurements.

Also keep in mind that the execution of each command involves a parser and a processor for each file, and a comparator for generating the diffs. Roles are well-defined:

- parsers (which are automatically generated by gramgen) translate a TOL file into a hierarchical parse tree implemented by means of the tol::pE class and its subclasses; see apgenlib/tol\_expressions.H for the general structure of the base class and the header file tpf/comparison/gen\_tol\_exp.H for the derived classes generated by gramgen

- processors (implemented in tpf/process\_tol.C and tpf/process\_record.C) prune individual Records (implemented as instances of the derived class tol::Record) and re-express them in terms of parser- independent objects defined in apgenlib/tol\_data.H.  In particular, each resource documented in the TOL gives rise to a tol::resource object which among other things contains a (potentially complete) history of resource values, indexed by both linear (integer) and time-valued indices. Assuming that it is known whether the resource should be interpolated or not - which is not the case presently - the history can be used to evaluate the value of any resource at any time within the scope of the TOL.

- the comparator (implemented in tpf/comparator.C) examines the processed data for both files, focusing on any discrepancy in time and/or value between the two files.

Back to command descriptions. It is pretty obvious that we are going to need commands for the following types
of actions:

- actions that require reading the input file(s).  Obviously, the first thing that should happen in any "compare session" is open the files and take a first look, without investing a lot of time.  Other actions may go back and parse the file for more detail.

 - actions that only involve data that were extracted previously.

### Interpreter State

In order to break up a high-level command like "compare TOL files" into smaller chunks, one should design the interpreter so it has a well-defined state, and low-level commands can be used to cause transitions between states. A starting point is to break up the 'compare' command into chunks that perform the following activities:

1. Read the metadata if they exist or, if they don't, read the initial resource records to establish (a) the list of resources and (b) their initial values.
2. Compare metadata between the TOLs and identify any diffs. Optionally, point out difference in the timing of the initial record. Optionally, produce a report with lists of offending resource or container names. Optionally, point out differences in initial values.
3. Take an initial peek at the body of the TOLs to get a sense of how well the two files match. The amount of parsing done in this step could be specified as a number of records, a (wall clock) CPU processing time or a time value greater than the initial record time.
4. Compare the partial list of records between the two files. At this point, the focus is on whether any significant differences show up. Optionally, produce a report containing the number of discrepancies, lists of record differences and/or histories of selected resources or containers.
5. Parse the entire TOLs.
6. Produce a report at various levels of detail:
    - number of discrepancies
    - statistics of discrepancies
    - joint or separate resource histories for selected resources

Two sets of interpreter states are required to support the above commands. The first set, shown in the table below, controls the TOL parsing process and how extensive the user wants it to be. These are the "control states" for the interpreter.

Control State | Description
------------- | -----------
Start | The state the interpreter is in when the application is started
Initial | The metadata or the initial resource records have been read and a database of resources has been established for each file
Partial | A portion of each TOL file has been read based on the criteria specified in the "peek" command
Final | All resources have been fully processed

The second set of interpreter states concerns the desired granularity of the data generated by the TOL processors as they parse records from the files. For example, in a regression test setting, one is only interested in a PASS/FAIL alternative; no further details are necessary. On the other hand, debugging a complex modeling or TOL reporting issue will require detailed comparisons between two TOLs. In such a situation, the TOL processing threads will have to work harder and extract all the information required to produce the required output. The table below provides a list of "granularity states" that supports these concepts.

Granularity State | Description
----------------- | -----------
Pass/Fail | As it indicates. The parsers can stop parsing as soon as a discrepancy is found. Output is minimal.
Anomaly Count | Keep aggregate data concerning the nature and frequency of discrepancies, but do not build up a database of individual records
Detailed Diff | Store records that differ in the two TOL files for a specific set of resources (which could be all of them)
Full History | Store all records for a specified set of resources

The last of these states has the finest granularity. Regardless of the method used to store the two histories, it should be easy to process the histories to produce output reports highlighting differences in the record times and/or resource values found in the two TOLs.

### Commands

Based on the above, the following table lists commands that are necessary to read and process a pair of TOLs.

Command | Options | Effect
------- | ------- | ------
OPEN | \_ | Read the metadata if they exist or, if they don't, read the initial resource records to establish (a) the list of resources and (b) their initial values.
PEEK | MaxRecords | Read MaxRecords records from the file(s)
_ditto_ | CPU | Read until the specified amount of CPU time has elapsed or SCET (the time stamp at which to stop parsing) |
_ditto_ | SCET | Read until the specified time stamp has been reached
READ | \_ | Parse the entire TOL file(s)
COMPARE | Metadata | Identify any diffs between the Metadata of the two TOLs. Optionally, point out difference in the timing of the initial record. Optionally, produce a report with lists of offending resource or container names. Optionally, point out differences in initial values.
_ditto_ | Records | Compare the partial list of records between the two files. At this point, the focus is on whether any significant differences show up. Optionally, produce a report containing the number of discrepancies, lists of record differences and/or histories of selected resources or containers.
OUTPUT | Output file name, list of container or resource names | Produce a report at various levels of detail: number of discrepancies, statistics of discrepancies, joint or separate resource histories for selected resources

### READ FILE options

Whenever (a) file(s) needs to be read, it must be parsed and processed. This implies that for each file, one must launching 2 threads with parsing and processing ability, respectively. If the files are to be compared, a fifth "comparator" thread must be launched.

We will refer to the data produced by a parsing thread as "parse trees", to the data produced by a processing thread as "measurements", and to data produced by the comparison thread as "diagnostics".

Let us try to figure out which options should be available for each READ FILE command, and what the corresponding measurements should be.

Note: since we don't yet have metadata files, we limit ourselves to resources; activity measurements will be much easier to define once activity definitions become available.

 Option | Parameters | Description | Measurement(s)
 ------ | ---------- | ----------- | --------------
 INITIAL | None | Quick peek at TOL data | list of resources and containers, initial time stamp, resource data (name, data type, initial value)
 TIME INTERVAL | from-time, to-time, opt. list of res. or containers | reads records over the specified interval | partial history/ies of specified resource(s)
 RECORDS | from-record, to-record, opt.  list of res.  or containers | ditto | ditto
 CPU TIME | wall-clock duration of the desired run, optional list of res.  or containers | reads records until it runs out of time | ditto
 ALL | optional list of resources or containers | reads all records per- taining to the specified re- sources and/or containers | full resource histories

The above describes what each parser/processor combination is instructed to do based on command code and parameters. However, in comparison mode - that is to say, when two separate files are being read and processed simultaneously - the process may be interrupted when the comparator thread detects a discrepancy.

 ### Command Format

 Code | argument 1 | argument 2 | argument 3
 ---- | ---------- | ---------- | ----------
 INITIAL | file name 1 | [file name 2] | \_
 BODY | TIME INTERVAL | start (can be earlier than the first record) | end
 \_ | CPU TIME | seconds | \_
 \_ | RECORDS | number of records | \_


### OUTPUT Commands

We need to specify how the TOL compararor should format its report, i. e., the result of analyzing the measurements made by the processing threads.

 Code | Arguments | Semantics
 ---- | --------- | ---------
 OPEN | List of one or two file names | Get initial section and report the first time tag
 DIFF | Struct with a max number of records of resources that disagree or a max time | Report joint history over the specified span
 HISTORY | Struct with (1) a list of container or resource names, (2) a format argument indicating whether to report separate or joint histories, (3) an optional time interval | Depending on argument values, report a joint history or separate histories for each resource in the list

DIFF only makes sense if two files have been opened.  HISTORY makes sense even if only one file was read, but in that case the format argument is not required.

A "joint history" is similar to a resource TOL but with four entries instead of two for each record where the two files differ:

 Record appearance | Meaning
 ----------------- | -------
 Time          Val  | Both files agree
 Time   Val1   Val2 | Both have this tag but values disagree
 Time   \-  Val  \- | Only file 1 has this record
 \-    Time \-  Val | Only file 2 has this record

For compatibility for future web-based implementation (e. g.  a debugger), JSON will be used to format the actual data.  The mapping to JSON is pretty obvious as far as commands are concerned. For output data, white space (which is ignored by JSON) will be used to make the format intuitively clear.

## Record Processing

### Use Cases

 Command | What we should do
 ------- | -----------------
 INITIAL | (1) grab resource name and initial value; (2) define corresponding entry in the static members of the _resource_ class
 TIME INTERVAL | Build up _resource::history_ for each resource as long as the stream of data is active
 CPU TIME | ditto
 RECORDS | ditto
 ALL | ditto
